{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Model\n",
    "**Model:** Logistic Regression  \n",
    "**Accuracy:** 85%  \n",
    "**Goal:** Predict at-risk customers and support retention strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1. IMPORTS ───────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries loaded successfully ✅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2. LOAD DATA ─────────────────────────────────────────────\n",
    "# Replace with your actual data source\n",
    "# df = pd.read_csv('customer_data.csv')\n",
    "# df = pd.read_sql(query, connection)\n",
    "\n",
    "# Sample synthetic dataset for demonstration\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'customer_id':         [f'C-{i:04d}' for i in range(n)],\n",
    "    'days_since_login':    np.random.randint(0, 90, n),\n",
    "    'support_tickets':     np.random.poisson(2, n),\n",
    "    'feature_adoption':    np.random.uniform(0, 1, n),\n",
    "    'contract_age_months': np.random.randint(1, 36, n),\n",
    "    'nps_score':           np.random.randint(0, 10, n),\n",
    "    'payment_delays':      np.random.poisson(0.5, n),\n",
    "    'monthly_revenue':     np.random.uniform(100, 2000, n),\n",
    "    'segment':             np.random.choice(['Enterprise','Mid-Market','SMB','Freemium'], n),\n",
    "})\n",
    "\n",
    "# Simulate churn label based on feature signals\n",
    "churn_prob = (\n",
    "    0.3 * (df['days_since_login'] / 90) +\n",
    "    0.2 * (df['support_tickets'] / 10).clip(0, 1) +\n",
    "    0.2 * (1 - df['feature_adoption']) +\n",
    "    0.1 * (1 - df['nps_score'] / 10) +\n",
    "    0.2 * (df['payment_delays'] / 5).clip(0, 1)\n",
    ")\n",
    "df['churn'] = (churn_prob + np.random.normal(0, 0.1, n) > 0.5).astype(int)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Churn rate: {df[\"churn\"].mean():.1%}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3. EXPLORATORY DATA ANALYSIS ─────────────────────────────\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Customer Churn - Exploratory Data Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "features = ['days_since_login', 'support_tickets', 'feature_adoption',\n",
    "            'nps_score', 'contract_age_months', 'payment_delays']\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), features):\n",
    "    df.groupby('churn')[feat].plot.kde(ax=ax, legend=True)\n",
    "    ax.set_title(feat.replace('_', ' ').title())\n",
    "    ax.legend(['Retained', 'Churned'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Churn by segment\n",
    "print('\\nChurn Rate by Segment:')\n",
    "print(df.groupby('segment')['churn'].mean().sort_values(ascending=False).map('{:.1%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4. FEATURE ENGINEERING ───────────────────────────────────\n",
    "features = [\n",
    "    'days_since_login',\n",
    "    'support_tickets',\n",
    "    'feature_adoption',\n",
    "    'contract_age_months',\n",
    "    'nps_score',\n",
    "    'payment_delays'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['churn']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}')\n",
    "print(f'Test samples:     {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5. TRAIN MODELS ──────────────────────────────────────────\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest':        RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM':                  SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        'Accuracy':  accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall':    recall_score(y_test, y_pred),\n",
    "        'F1 Score':  f1_score(y_test, y_pred),\n",
    "        'AUC-ROC':   roc_auc_score(y_test, y_prob),\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print('\\nModel Comparison:')\n",
    "print(results_df.applymap('{:.3f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 6. BEST MODEL — LOGISTIC REGRESSION ──────────────────────\n",
    "best_model = models['Logistic Regression']\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('=== Logistic Regression — Classification Report ===')\n",
    "print(classification_report(y_test, y_pred, target_names=['Retained', 'Churned']))\n",
    "\n",
    "# Confusion Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Retained', 'Churned'],\n",
    "            yticklabels=['Retained', 'Churned'])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "axes[1].plot(fpr, tpr, color='#06b6d4', lw=2, label=f'AUC = {auc:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 7. FEATURE IMPORTANCE ────────────────────────────────────\n",
    "importance = pd.DataFrame({\n",
    "    'Feature':    features,\n",
    "    'Coefficient': np.abs(best_model.coef_[0])\n",
    "}).sort_values('Coefficient', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.barh(importance['Feature'], importance['Coefficient'], color='#06b6d4')\n",
    "plt.title('Feature Importance — Logistic Regression Coefficients', fontweight='bold')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop Churn Predictors:')\n",
    "for _, row in importance.sort_values('Coefficient', ascending=False).iterrows():\n",
    "    print(f'  {row[\"Feature\"]:<30} {row[\"Coefficient\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 8. SCORE ALL CUSTOMERS & FLAG AT-RISK ────────────────────\n",
    "X_all_scaled = scaler.transform(df[features])\n",
    "df['churn_probability'] = best_model.predict_proba(X_all_scaled)[:, 1]\n",
    "df['churn_score']       = (df['churn_probability'] * 100).round(1)\n",
    "df['risk_level']        = pd.cut(\n",
    "    df['churn_score'],\n",
    "    bins=[0, 50, 70, 85, 100],\n",
    "    labels=['Low', 'Medium', 'High', 'Critical']\n",
    ")\n",
    "\n",
    "at_risk = df[df['churn_score'] >= 70].sort_values('churn_score', ascending=False)\n",
    "\n",
    "print(f'Total customers scored: {len(df):,}')\n",
    "print(f'At-risk customers (score ≥ 70): {len(at_risk):,}')\n",
    "print(f'Critical (score ≥ 85): {len(df[df[\"churn_score\"] >= 85]):,}')\n",
    "print('\\nTop 10 At-Risk Customers:')\n",
    "print(at_risk[['customer_id', 'churn_score', 'risk_level', 'monthly_revenue', 'segment']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 9. EXPORT RESULTS ────────────────────────────────────────\n",
    "# Export at-risk customers for dashboard or CRM\n",
    "at_risk[['customer_id', 'churn_score', 'risk_level', 'monthly_revenue', 'segment']]\\\n",
    "    .to_csv('at_risk_customers.csv', index=False)\n",
    "\n",
    "print('✅ at_risk_customers.csv exported successfully!')\n",
    "print('Ready to load into dashboard or CRM for follow-up actions.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
